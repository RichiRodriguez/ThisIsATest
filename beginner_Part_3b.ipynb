{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04QgGZc9bF5D"
   },
   "source": [
    "# Import and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "\n",
    "# Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FP5258xjs-v"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPZ68wASog_I"
   },
   "source": [
    "Build the `tf.keras.Sequential` model by stacking layers. Choose an optimizer and loss function for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_set = list(range(0,50))\n",
    "graph_epochs = []\n",
    "graph_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------> Currently training the model with 0 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "10000/1 - 1s - loss: 2.4069 - accuracy: 0.0871\n",
      "\n",
      "-------------------------> Currently training the model with 1 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2928 - accuracy: 0.9156\n",
      "10000/1 - 1s - loss: 0.0784 - accuracy: 0.9600\n",
      "\n",
      "-------------------------> Currently training the model with 2 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2939 - accuracy: 0.9145\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1393 - accuracy: 0.9585\n",
      "10000/1 - 1s - loss: 0.0653 - accuracy: 0.9680\n",
      "\n",
      "-------------------------> Currently training the model with 3 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.2974 - accuracy: 0.9138\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.1459 - accuracy: 0.9561\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1075 - accuracy: 0.9672\n",
      "10000/1 - 1s - loss: 0.0461 - accuracy: 0.9733\n",
      "\n",
      "-------------------------> Currently training the model with 4 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2899 - accuracy: 0.9161\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1408 - accuracy: 0.9592\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1045 - accuracy: 0.9684\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0866 - accuracy: 0.9727\n",
      "10000/1 - 1s - loss: 0.0397 - accuracy: 0.9775\n",
      "\n",
      "-------------------------> Currently training the model with 5 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2981 - accuracy: 0.9125\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1459 - accuracy: 0.9562\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1087 - accuracy: 0.9663\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0901 - accuracy: 0.9714\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0751 - accuracy: 0.9758\n",
      "10000/1 - 1s - loss: 0.0384 - accuracy: 0.9769\n",
      "\n",
      "-------------------------> Currently training the model with 6 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2959 - accuracy: 0.9127\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1434 - accuracy: 0.9576\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.1083 - accuracy: 0.9665\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0874 - accuracy: 0.9734\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0762 - accuracy: 0.9759\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0641 - accuracy: 0.9798\n",
      "10000/1 - 1s - loss: 0.0372 - accuracy: 0.9766\n",
      "\n",
      "-------------------------> Currently training the model with 7 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/7\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2913 - accuracy: 0.9161\n",
      "Epoch 2/7\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1415 - accuracy: 0.9582\n",
      "Epoch 3/7\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1058 - accuracy: 0.9682\n",
      "Epoch 4/7\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0874 - accuracy: 0.9729\n",
      "Epoch 5/7\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0738 - accuracy: 0.9772\n",
      "Epoch 6/7\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0642 - accuracy: 0.9795\n",
      "Epoch 7/7\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0566 - accuracy: 0.9812\n",
      "10000/1 - 1s - loss: 0.0345 - accuracy: 0.9793\n",
      "\n",
      "-------------------------> Currently training the model with 8 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.2988 - accuracy: 0.9131\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1416 - accuracy: 0.9578\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1077 - accuracy: 0.9672\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0861 - accuracy: 0.9732\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0750 - accuracy: 0.9766\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0681 - accuracy: 0.9780\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0593 - accuracy: 0.9807\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0528 - accuracy: 0.9828\n",
      "10000/1 - 1s - loss: 0.0364 - accuracy: 0.9800\n",
      "\n",
      "-------------------------> Currently training the model with 9 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/9\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2972 - accuracy: 0.9136\n",
      "Epoch 2/9\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1388 - accuracy: 0.9589\n",
      "Epoch 3/9\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1045 - accuracy: 0.9687\n",
      "Epoch 4/9\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0864 - accuracy: 0.9739\n",
      "Epoch 5/9\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0742 - accuracy: 0.9772\n",
      "Epoch 6/9\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0642 - accuracy: 0.9796\n",
      "Epoch 7/9\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0594 - accuracy: 0.9803\n",
      "Epoch 8/9\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0521 - accuracy: 0.9830\n",
      "Epoch 9/9\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0491 - accuracy: 0.9844\n",
      "10000/1 - 1s - loss: 0.0370 - accuracy: 0.9781\n",
      "\n",
      "-------------------------> Currently training the model with 10 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.2940 - accuracy: 0.9154\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1445 - accuracy: 0.9575\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1095 - accuracy: 0.9670\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0887 - accuracy: 0.9719\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0770 - accuracy: 0.9760\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0667 - accuracy: 0.9787\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0608 - accuracy: 0.9807\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0544 - accuracy: 0.9819\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0482 - accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0464 - accuracy: 0.9848\n",
      "10000/1 - 1s - loss: 0.0366 - accuracy: 0.9788\n",
      "\n",
      "-------------------------> Currently training the model with 11 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/11\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2967 - accuracy: 0.9133\n",
      "Epoch 2/11\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1458 - accuracy: 0.9564\n",
      "Epoch 3/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1081 - accuracy: 0.9667\n",
      "Epoch 4/11\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0901 - accuracy: 0.9725\n",
      "Epoch 5/11\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0754 - accuracy: 0.9758\n",
      "Epoch 6/11\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0645 - accuracy: 0.9797\n",
      "Epoch 7/11\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0574 - accuracy: 0.9816\n",
      "Epoch 8/11\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0504 - accuracy: 0.9840\n",
      "Epoch 9/11\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0492 - accuracy: 0.9837\n",
      "Epoch 10/11\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0454 - accuracy: 0.9850\n",
      "Epoch 11/11\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0412 - accuracy: 0.9861\n",
      "10000/1 - 1s - loss: 0.0350 - accuracy: 0.9814\n",
      "\n",
      "-------------------------> Currently training the model with 12 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3021 - accuracy: 0.9113\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1459 - accuracy: 0.9566\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1102 - accuracy: 0.9662\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0903 - accuracy: 0.9724\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0771 - accuracy: 0.9751\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0670 - accuracy: 0.9785\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0605 - accuracy: 0.9804\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0533 - accuracy: 0.9826\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0493 - accuracy: 0.9833\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0469 - accuracy: 0.9844\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0414 - accuracy: 0.9857\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0405 - accuracy: 0.9864\n",
      "10000/1 - 1s - loss: 0.0365 - accuracy: 0.9797\n",
      "\n",
      "-------------------------> Currently training the model with 13 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/13\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.2960 - accuracy: 0.9138\n",
      "Epoch 2/13\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1423 - accuracy: 0.9575\n",
      "Epoch 3/13\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1060 - accuracy: 0.9683\n",
      "Epoch 4/13\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0863 - accuracy: 0.9736\n",
      "Epoch 5/13\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0755 - accuracy: 0.9764\n",
      "Epoch 6/13\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0653 - accuracy: 0.9803\n",
      "Epoch 7/13\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0598 - accuracy: 0.9811\n",
      "Epoch 8/13\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0502 - accuracy: 0.9840\n",
      "Epoch 9/13\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0476 - accuracy: 0.9840\n",
      "Epoch 10/13\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0431 - accuracy: 0.9858\n",
      "Epoch 11/13\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0406 - accuracy: 0.9865\n",
      "Epoch 12/13\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0387 - accuracy: 0.9875\n",
      "Epoch 13/13\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0337 - accuracy: 0.9884\n",
      "10000/1 - 1s - loss: 0.0374 - accuracy: 0.9803\n",
      "\n",
      "-------------------------> Currently training the model with 14 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/14\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.2996 - accuracy: 0.9126\n",
      "Epoch 2/14\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1456 - accuracy: 0.9553\n",
      "Epoch 3/14\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1082 - accuracy: 0.9668\n",
      "Epoch 4/14\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0867 - accuracy: 0.9729\n",
      "Epoch 5/14\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0753 - accuracy: 0.9763\n",
      "Epoch 6/14\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0654 - accuracy: 0.9792\n",
      "Epoch 7/14\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0600 - accuracy: 0.9809\n",
      "Epoch 8/14\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0529 - accuracy: 0.9834\n",
      "Epoch 9/14\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0499 - accuracy: 0.9832\n",
      "Epoch 10/14\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0440 - accuracy: 0.9852\n",
      "Epoch 11/14\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0402 - accuracy: 0.9865\n",
      "Epoch 12/14\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0404 - accuracy: 0.9864\n",
      "Epoch 13/14\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0377 - accuracy: 0.9870\n",
      "Epoch 14/14\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0355 - accuracy: 0.9883\n",
      "10000/1 - 1s - loss: 0.0394 - accuracy: 0.9781\n",
      "\n",
      "-------------------------> Currently training the model with 15 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2983 - accuracy: 0.9130\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1447 - accuracy: 0.9567\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1089 - accuracy: 0.9667\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0885 - accuracy: 0.9734\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0764 - accuracy: 0.9764\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0664 - accuracy: 0.9788\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0585 - accuracy: 0.9814\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0513 - accuracy: 0.9830\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0503 - accuracy: 0.9838\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0424 - accuracy: 0.9855\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0417 - accuracy: 0.9858\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0384 - accuracy: 0.9874\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0376 - accuracy: 0.9871\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0345 - accuracy: 0.9885\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0334 - accuracy: 0.9882\n",
      "10000/1 - 1s - loss: 0.0384 - accuracy: 0.9798\n",
      "\n",
      "-------------------------> Currently training the model with 16 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/16\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3002 - accuracy: 0.9132\n",
      "Epoch 2/16\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1459 - accuracy: 0.9563\n",
      "Epoch 3/16\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.1115 - accuracy: 0.9664\n",
      "Epoch 4/16\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0890 - accuracy: 0.9725\n",
      "Epoch 5/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0770 - accuracy: 0.9757\n",
      "Epoch 6/16\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0674 - accuracy: 0.9793\n",
      "Epoch 7/16\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0609 - accuracy: 0.9804\n",
      "Epoch 8/16\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0552 - accuracy: 0.9816\n",
      "Epoch 9/16\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0482 - accuracy: 0.9839\n",
      "Epoch 10/16\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0461 - accuracy: 0.9852\n",
      "Epoch 11/16\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0429 - accuracy: 0.9856\n",
      "Epoch 12/16\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0398 - accuracy: 0.9866\n",
      "Epoch 13/16\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0384 - accuracy: 0.9873\n",
      "Epoch 14/16\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0336 - accuracy: 0.9890\n",
      "Epoch 15/16\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0329 - accuracy: 0.9886\n",
      "Epoch 16/16\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0308 - accuracy: 0.9891\n",
      "10000/1 - 1s - loss: 0.0357 - accuracy: 0.9811\n",
      "\n",
      "-------------------------> Currently training the model with 17 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/17\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.2946 - accuracy: 0.9154\n",
      "Epoch 2/17\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1442 - accuracy: 0.9567\n",
      "Epoch 3/17\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1064 - accuracy: 0.9677\n",
      "Epoch 4/17\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0880 - accuracy: 0.9727\n",
      "Epoch 5/17\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0752 - accuracy: 0.9757\n",
      "Epoch 6/17\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0654 - accuracy: 0.9788\n",
      "Epoch 7/17\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0614 - accuracy: 0.9798\n",
      "Epoch 8/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0527 - accuracy: 0.9830\n",
      "Epoch 9/17\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0471 - accuracy: 0.9841\n",
      "Epoch 10/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0432 - accuracy: 0.9858\n",
      "Epoch 11/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0426 - accuracy: 0.9855\n",
      "Epoch 12/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0391 - accuracy: 0.9871\n",
      "Epoch 13/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0382 - accuracy: 0.9869\n",
      "Epoch 14/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0347 - accuracy: 0.9883\n",
      "Epoch 15/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0328 - accuracy: 0.9893\n",
      "Epoch 16/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0309 - accuracy: 0.9891\n",
      "Epoch 17/17\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0303 - accuracy: 0.9893\n",
      "10000/1 - 1s - loss: 0.0390 - accuracy: 0.9825\n",
      "\n",
      "-------------------------> Currently training the model with 18 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/18\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.2986 - accuracy: 0.9128\n",
      "Epoch 2/18\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.1469 - accuracy: 0.9560\n",
      "Epoch 3/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1114 - accuracy: 0.9669\n",
      "Epoch 4/18\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0920 - accuracy: 0.9719\n",
      "Epoch 5/18\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0769 - accuracy: 0.9759\n",
      "Epoch 6/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0683 - accuracy: 0.9791\n",
      "Epoch 7/18\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0610 - accuracy: 0.9805\n",
      "Epoch 8/18\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0535 - accuracy: 0.9824\n",
      "Epoch 9/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0516 - accuracy: 0.9835\n",
      "Epoch 10/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0471 - accuracy: 0.9843\n",
      "Epoch 11/18\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0447 - accuracy: 0.9854\n",
      "Epoch 12/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0389 - accuracy: 0.9868\n",
      "Epoch 13/18\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0371 - accuracy: 0.9878\n",
      "Epoch 14/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0343 - accuracy: 0.9887\n",
      "Epoch 15/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0329 - accuracy: 0.9889\n",
      "Epoch 16/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0318 - accuracy: 0.9888\n",
      "Epoch 17/18\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0294 - accuracy: 0.9898\n",
      "Epoch 18/18\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0301 - accuracy: 0.9894\n",
      "10000/1 - 1s - loss: 0.0402 - accuracy: 0.9790\n",
      "\n",
      "-------------------------> Currently training the model with 19 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/19\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2966 - accuracy: 0.9141\n",
      "Epoch 2/19\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.1387 - accuracy: 0.9592\n",
      "Epoch 3/19\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.1041 - accuracy: 0.9680\n",
      "Epoch 4/19\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0860 - accuracy: 0.9734\n",
      "Epoch 5/19\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0725 - accuracy: 0.9770\n",
      "Epoch 6/19\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0640 - accuracy: 0.9800\n",
      "Epoch 7/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0560 - accuracy: 0.9819\n",
      "Epoch 8/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0512 - accuracy: 0.9834\n",
      "Epoch 9/19\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0458 - accuracy: 0.9851\n",
      "Epoch 10/19\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0422 - accuracy: 0.9861\n",
      "Epoch 11/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0406 - accuracy: 0.9865\n",
      "Epoch 12/19\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0359 - accuracy: 0.9880\n",
      "Epoch 13/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0354 - accuracy: 0.9879\n",
      "Epoch 14/19\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0320 - accuracy: 0.9891\n",
      "Epoch 15/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0311 - accuracy: 0.9889\n",
      "Epoch 16/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0289 - accuracy: 0.9902\n",
      "Epoch 17/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0291 - accuracy: 0.9899\n",
      "Epoch 18/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0264 - accuracy: 0.9912\n",
      "Epoch 19/19\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0261 - accuracy: 0.9906\n",
      "10000/1 - 1s - loss: 0.0412 - accuracy: 0.9797\n",
      "\n",
      "-------------------------> Currently training the model with 20 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2904 - accuracy: 0.9168\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1407 - accuracy: 0.9574\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1060 - accuracy: 0.9678\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0881 - accuracy: 0.9733\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0730 - accuracy: 0.9772\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0644 - accuracy: 0.9799\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0601 - accuracy: 0.9806\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0517 - accuracy: 0.9840\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0467 - accuracy: 0.9844\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0443 - accuracy: 0.9852\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0383 - accuracy: 0.9873\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0378 - accuracy: 0.9872\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0354 - accuracy: 0.9876\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0322 - accuracy: 0.9887\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0320 - accuracy: 0.9885\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0305 - accuracy: 0.9890\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0292 - accuracy: 0.9907\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0281 - accuracy: 0.9904\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0259 - accuracy: 0.9915\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0242 - accuracy: 0.9916\n",
      "10000/1 - 1s - loss: 0.0406 - accuracy: 0.9810\n",
      "\n",
      "-------------------------> Currently training the model with 21 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/21\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.2920 - accuracy: 0.9151\n",
      "Epoch 2/21\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1421 - accuracy: 0.9575\n",
      "Epoch 3/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1065 - accuracy: 0.9672\n",
      "Epoch 4/21\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0887 - accuracy: 0.9726\n",
      "Epoch 5/21\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0766 - accuracy: 0.9759\n",
      "Epoch 6/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0665 - accuracy: 0.9789\n",
      "Epoch 7/21\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0591 - accuracy: 0.9811\n",
      "Epoch 8/21\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0513 - accuracy: 0.9833\n",
      "Epoch 9/21\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0490 - accuracy: 0.9841\n",
      "Epoch 10/21\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0446 - accuracy: 0.9852\n",
      "Epoch 11/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0400 - accuracy: 0.9867\n",
      "Epoch 12/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0379 - accuracy: 0.9871\n",
      "Epoch 13/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0357 - accuracy: 0.9879\n",
      "Epoch 14/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0331 - accuracy: 0.9888\n",
      "Epoch 15/21\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0329 - accuracy: 0.9885\n",
      "Epoch 16/21\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0306 - accuracy: 0.9897\n",
      "Epoch 17/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0293 - accuracy: 0.9898\n",
      "Epoch 18/21\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0272 - accuracy: 0.9907\n",
      "Epoch 19/21\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0281 - accuracy: 0.9899\n",
      "Epoch 20/21\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0245 - accuracy: 0.9908\n",
      "Epoch 21/21\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0240 - accuracy: 0.9918\n",
      "10000/1 - 1s - loss: 0.0417 - accuracy: 0.9815\n",
      "\n",
      "-------------------------> Currently training the model with 22 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/22\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2987 - accuracy: 0.9140\n",
      "Epoch 2/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1437 - accuracy: 0.9577\n",
      "Epoch 3/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1069 - accuracy: 0.9679\n",
      "Epoch 4/22\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0870 - accuracy: 0.9729\n",
      "Epoch 5/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0751 - accuracy: 0.9759\n",
      "Epoch 6/22\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0652 - accuracy: 0.9796\n",
      "Epoch 7/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0582 - accuracy: 0.9810\n",
      "Epoch 8/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0510 - accuracy: 0.9837\n",
      "Epoch 9/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0480 - accuracy: 0.9840\n",
      "Epoch 10/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0449 - accuracy: 0.9849\n",
      "Epoch 11/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0399 - accuracy: 0.9869\n",
      "Epoch 12/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0390 - accuracy: 0.9875\n",
      "Epoch 13/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0355 - accuracy: 0.9884\n",
      "Epoch 14/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0346 - accuracy: 0.9889\n",
      "Epoch 15/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0333 - accuracy: 0.9886\n",
      "Epoch 16/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0311 - accuracy: 0.9894\n",
      "Epoch 17/22\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0294 - accuracy: 0.9898\n",
      "Epoch 18/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0281 - accuracy: 0.9900\n",
      "Epoch 19/22\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0272 - accuracy: 0.9907\n",
      "Epoch 20/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0269 - accuracy: 0.9907\n",
      "Epoch 21/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0267 - accuracy: 0.9909\n",
      "Epoch 22/22\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0235 - accuracy: 0.9919\n",
      "10000/1 - 1s - loss: 0.0415 - accuracy: 0.9807\n",
      "\n",
      "-------------------------> Currently training the model with 23 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/23\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2953 - accuracy: 0.9153\n",
      "Epoch 2/23\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1401 - accuracy: 0.9584\n",
      "Epoch 3/23\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1068 - accuracy: 0.9677\n",
      "Epoch 4/23\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0885 - accuracy: 0.9726\n",
      "Epoch 5/23\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0770 - accuracy: 0.9763\n",
      "Epoch 6/23\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0642 - accuracy: 0.9797\n",
      "Epoch 7/23\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0575 - accuracy: 0.9817\n",
      "Epoch 8/23\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0541 - accuracy: 0.9829\n",
      "Epoch 9/23\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0482 - accuracy: 0.9845\n",
      "Epoch 10/23\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0457 - accuracy: 0.9851\n",
      "Epoch 11/23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0412 - accuracy: 0.9861\n",
      "Epoch 12/23\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0394 - accuracy: 0.9867\n",
      "Epoch 13/23\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0357 - accuracy: 0.9880\n",
      "Epoch 14/23\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0348 - accuracy: 0.9884\n",
      "Epoch 15/23\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0319 - accuracy: 0.9893\n",
      "Epoch 16/23\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0316 - accuracy: 0.9897\n",
      "Epoch 17/23\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0293 - accuracy: 0.9896\n",
      "Epoch 18/23\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0280 - accuracy: 0.9905\n",
      "Epoch 19/23\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0255 - accuracy: 0.9912\n",
      "Epoch 20/23\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0285 - accuracy: 0.9903\n",
      "Epoch 21/23\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0261 - accuracy: 0.9908\n",
      "Epoch 22/23\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0241 - accuracy: 0.9917\n",
      "Epoch 23/23\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0246 - accuracy: 0.9917\n",
      "10000/1 - 1s - loss: 0.0415 - accuracy: 0.9813\n",
      "\n",
      "-------------------------> Currently training the model with 24 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/24\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.2995 - accuracy: 0.9129\n",
      "Epoch 2/24\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1436 - accuracy: 0.9571\n",
      "Epoch 3/24\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1083 - accuracy: 0.9672\n",
      "Epoch 4/24\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0870 - accuracy: 0.9724\n",
      "Epoch 5/24\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0756 - accuracy: 0.9770\n",
      "Epoch 6/24\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0645 - accuracy: 0.9794\n",
      "Epoch 7/24\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0567 - accuracy: 0.9823\n",
      "Epoch 8/24\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0530 - accuracy: 0.9822\n",
      "Epoch 9/24\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0468 - accuracy: 0.9843\n",
      "Epoch 10/24\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0435 - accuracy: 0.9855\n",
      "Epoch 11/24\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0413 - accuracy: 0.9864\n",
      "Epoch 12/24\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0374 - accuracy: 0.9881\n",
      "Epoch 13/24\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0357 - accuracy: 0.9883\n",
      "Epoch 14/24\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0328 - accuracy: 0.9885\n",
      "Epoch 15/24\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0332 - accuracy: 0.9882\n",
      "Epoch 16/24\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0305 - accuracy: 0.9894\n",
      "Epoch 17/24\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 18/24\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0283 - accuracy: 0.9903\n",
      "Epoch 19/24\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0271 - accuracy: 0.9906\n",
      "Epoch 20/24\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0267 - accuracy: 0.9911\n",
      "Epoch 21/24\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0253 - accuracy: 0.9908\n",
      "Epoch 22/24\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0260 - accuracy: 0.9911\n",
      "Epoch 23/24\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 24/24\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0225 - accuracy: 0.9923\n",
      "10000/1 - 1s - loss: 0.0477 - accuracy: 0.9797\n",
      "\n",
      "-------------------------> Currently training the model with 25 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2970 - accuracy: 0.9128\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1430 - accuracy: 0.9575\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1076 - accuracy: 0.9671\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0882 - accuracy: 0.9731\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0754 - accuracy: 0.9764\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0645 - accuracy: 0.9793\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0590 - accuracy: 0.9811\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0522 - accuracy: 0.9826\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0474 - accuracy: 0.9842\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0424 - accuracy: 0.9855\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0409 - accuracy: 0.9860\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0371 - accuracy: 0.9877\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0358 - accuracy: 0.9877\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0331 - accuracy: 0.9882\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0311 - accuracy: 0.9896\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0306 - accuracy: 0.9894\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0292 - accuracy: 0.9897\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0285 - accuracy: 0.9906\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0258 - accuracy: 0.9909\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0271 - accuracy: 0.9903\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0247 - accuracy: 0.9918\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0246 - accuracy: 0.9912\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0208 - accuracy: 0.9929\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0220 - accuracy: 0.9924\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0213 - accuracy: 0.9924\n",
      "10000/1 - 1s - loss: 0.0452 - accuracy: 0.9813\n",
      "\n",
      "-------------------------> Currently training the model with 26 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/26\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.2929 - accuracy: 0.9150\n",
      "Epoch 2/26\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.1441 - accuracy: 0.9581\n",
      "Epoch 3/26\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1074 - accuracy: 0.9675\n",
      "Epoch 4/26\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0888 - accuracy: 0.9726\n",
      "Epoch 5/26\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0736 - accuracy: 0.9772\n",
      "Epoch 6/26\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0637 - accuracy: 0.9793\n",
      "Epoch 7/26\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0574 - accuracy: 0.9822\n",
      "Epoch 8/26\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0500 - accuracy: 0.9837\n",
      "Epoch 9/26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0462 - accuracy: 0.9840\n",
      "Epoch 10/26\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0440 - accuracy: 0.9855\n",
      "Epoch 11/26\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0404 - accuracy: 0.9864\n",
      "Epoch 12/26\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0360 - accuracy: 0.9876\n",
      "Epoch 13/26\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0349 - accuracy: 0.9887\n",
      "Epoch 14/26\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0354 - accuracy: 0.9880\n",
      "Epoch 15/26\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0310 - accuracy: 0.9893\n",
      "Epoch 16/26\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0310 - accuracy: 0.9891\n",
      "Epoch 17/26\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0303 - accuracy: 0.9898\n",
      "Epoch 18/26\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0271 - accuracy: 0.9911\n",
      "Epoch 19/26\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0267 - accuracy: 0.9907\n",
      "Epoch 20/26\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0261 - accuracy: 0.9913\n",
      "Epoch 21/26\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0248 - accuracy: 0.9914\n",
      "Epoch 22/26\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0235 - accuracy: 0.9919\n",
      "Epoch 23/26\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0231 - accuracy: 0.9916\n",
      "Epoch 24/26\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0240 - accuracy: 0.9916\n",
      "Epoch 25/26\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0214 - accuracy: 0.9929\n",
      "Epoch 26/26\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0234 - accuracy: 0.9920\n",
      "10000/1 - 1s - loss: 0.0448 - accuracy: 0.9807\n",
      "\n",
      "-------------------------> Currently training the model with 27 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/27\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3002 - accuracy: 0.9136\n",
      "Epoch 2/27\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1443 - accuracy: 0.9575\n",
      "Epoch 3/27\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1076 - accuracy: 0.9676\n",
      "Epoch 4/27\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0879 - accuracy: 0.9727\n",
      "Epoch 5/27\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0762 - accuracy: 0.9759\n",
      "Epoch 6/27\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0654 - accuracy: 0.9789\n",
      "Epoch 7/27\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0585 - accuracy: 0.9811\n",
      "Epoch 8/27\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0538 - accuracy: 0.9823\n",
      "Epoch 9/27\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0480 - accuracy: 0.9840\n",
      "Epoch 10/27\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0439 - accuracy: 0.9857\n",
      "Epoch 11/27\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0413 - accuracy: 0.9856\n",
      "Epoch 12/27\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0394 - accuracy: 0.9870\n",
      "Epoch 13/27\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0368 - accuracy: 0.9873\n",
      "Epoch 14/27\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.0343 - accuracy: 0.9889\n",
      "Epoch 15/27\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0314 - accuracy: 0.9893\n",
      "Epoch 16/27\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0313 - accuracy: 0.9887\n",
      "Epoch 17/27\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0321 - accuracy: 0.9890\n",
      "Epoch 18/27\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0278 - accuracy: 0.9904\n",
      "Epoch 19/27\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0270 - accuracy: 0.9909\n",
      "Epoch 20/27\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0239 - accuracy: 0.9917\n",
      "Epoch 21/27\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0254 - accuracy: 0.9908\n",
      "Epoch 22/27\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0245 - accuracy: 0.9916\n",
      "Epoch 23/27\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0232 - accuracy: 0.9915\n",
      "Epoch 24/27\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0243 - accuracy: 0.9915\n",
      "Epoch 25/27\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0207 - accuracy: 0.9925\n",
      "Epoch 26/27\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0221 - accuracy: 0.9919\n",
      "Epoch 27/27\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0214 - accuracy: 0.9922\n",
      "10000/1 - 1s - loss: 0.0485 - accuracy: 0.9792\n",
      "\n",
      "-------------------------> Currently training the model with 28 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/28\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3025 - accuracy: 0.9123\n",
      "Epoch 2/28\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1433 - accuracy: 0.9576\n",
      "Epoch 3/28\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.1070 - accuracy: 0.9679\n",
      "Epoch 4/28\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0878 - accuracy: 0.9733\n",
      "Epoch 5/28\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0740 - accuracy: 0.9769\n",
      "Epoch 6/28\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0659 - accuracy: 0.9790\n",
      "Epoch 7/28\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0597 - accuracy: 0.9806\n",
      "Epoch 8/28\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0532 - accuracy: 0.9829\n",
      "Epoch 9/28\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0490 - accuracy: 0.9838\n",
      "Epoch 10/28\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0446 - accuracy: 0.9853\n",
      "Epoch 11/28\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0397 - accuracy: 0.9868\n",
      "Epoch 12/28\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0390 - accuracy: 0.9872\n",
      "Epoch 13/28\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0335 - accuracy: 0.9888\n",
      "Epoch 14/28\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0340 - accuracy: 0.9886\n",
      "Epoch 15/28\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0341 - accuracy: 0.9883\n",
      "Epoch 16/28\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0292 - accuracy: 0.9901\n",
      "Epoch 17/28\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0288 - accuracy: 0.9903\n",
      "Epoch 18/28\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 19/28\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0273 - accuracy: 0.9904\n",
      "Epoch 20/28\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0248 - accuracy: 0.9915\n",
      "Epoch 21/28\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0245 - accuracy: 0.9915\n",
      "Epoch 22/28\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0229 - accuracy: 0.9920\n",
      "Epoch 23/28\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0220 - accuracy: 0.9922\n",
      "Epoch 24/28\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0234 - accuracy: 0.9919\n",
      "Epoch 25/28\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0225 - accuracy: 0.9923\n",
      "Epoch 26/28\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0206 - accuracy: 0.9929\n",
      "Epoch 27/28\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0206 - accuracy: 0.9929\n",
      "Epoch 28/28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0228 - accuracy: 0.9923\n",
      "10000/1 - 1s - loss: 0.0446 - accuracy: 0.9812\n",
      "\n",
      "-------------------------> Currently training the model with 29 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/29\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.2923 - accuracy: 0.9145\n",
      "Epoch 2/29\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1410 - accuracy: 0.9582\n",
      "Epoch 3/29\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.1065 - accuracy: 0.9677\n",
      "Epoch 4/29\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0864 - accuracy: 0.9731\n",
      "Epoch 5/29\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0723 - accuracy: 0.9770\n",
      "Epoch 6/29\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0642 - accuracy: 0.9797\n",
      "Epoch 7/29\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0583 - accuracy: 0.9808\n",
      "Epoch 8/29\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0505 - accuracy: 0.9839\n",
      "Epoch 9/29\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0468 - accuracy: 0.9844\n",
      "Epoch 10/29\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0432 - accuracy: 0.9860\n",
      "Epoch 11/29\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0408 - accuracy: 0.9859\n",
      "Epoch 12/29\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0375 - accuracy: 0.9872\n",
      "Epoch 13/29\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0374 - accuracy: 0.9871\n",
      "Epoch 14/29\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0337 - accuracy: 0.9884\n",
      "Epoch 15/29\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0329 - accuracy: 0.9889\n",
      "Epoch 16/29\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0310 - accuracy: 0.9888\n",
      "Epoch 17/29\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0297 - accuracy: 0.9897\n",
      "Epoch 18/29\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 19/29\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0280 - accuracy: 0.9902\n",
      "Epoch 20/29\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0263 - accuracy: 0.9908\n",
      "Epoch 21/29\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0251 - accuracy: 0.9916\n",
      "Epoch 22/29\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0248 - accuracy: 0.9908\n",
      "Epoch 23/29\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0235 - accuracy: 0.9917\n",
      "Epoch 24/29\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0218 - accuracy: 0.9923\n",
      "Epoch 25/29\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0210 - accuracy: 0.9928\n",
      "Epoch 26/29\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0232 - accuracy: 0.9918\n",
      "Epoch 27/29\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0215 - accuracy: 0.9925\n",
      "Epoch 28/29\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0208 - accuracy: 0.9924\n",
      "Epoch 29/29\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0196 - accuracy: 0.9934\n",
      "10000/1 - 1s - loss: 0.0416 - accuracy: 0.9824\n",
      "\n",
      "-------------------------> Currently training the model with 30 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2889 - accuracy: 0.9160\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1392 - accuracy: 0.9590\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1046 - accuracy: 0.9678\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0877 - accuracy: 0.9734\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0739 - accuracy: 0.9772\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0648 - accuracy: 0.9797\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0574 - accuracy: 0.9823\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0534 - accuracy: 0.9825\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0474 - accuracy: 0.9844\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0438 - accuracy: 0.9854\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0406 - accuracy: 0.9861\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0386 - accuracy: 0.9870\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0356 - accuracy: 0.9882\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0323 - accuracy: 0.9891\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0300 - accuracy: 0.9901\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0310 - accuracy: 0.9895\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0307 - accuracy: 0.9893\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0275 - accuracy: 0.9908\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0251 - accuracy: 0.9912\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0256 - accuracy: 0.9910\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0262 - accuracy: 0.9912\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0240 - accuracy: 0.9917\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0238 - accuracy: 0.9917\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0223 - accuracy: 0.9923\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0205 - accuracy: 0.9933\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0212 - accuracy: 0.9926\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0196 - accuracy: 0.9935\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0206 - accuracy: 0.9930\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0203 - accuracy: 0.9929\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0201 - accuracy: 0.9929\n",
      "10000/1 - 1s - loss: 0.0466 - accuracy: 0.9817\n",
      "\n",
      "-------------------------> Currently training the model with 31 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/31\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.2991 - accuracy: 0.9128\n",
      "Epoch 2/31\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1439 - accuracy: 0.9568\n",
      "Epoch 3/31\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1081 - accuracy: 0.9672\n",
      "Epoch 4/31\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0881 - accuracy: 0.9730\n",
      "Epoch 5/31\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0759 - accuracy: 0.9765\n",
      "Epoch 6/31\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0628 - accuracy: 0.9801\n",
      "Epoch 7/31\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0581 - accuracy: 0.9812\n",
      "Epoch 8/31\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0514 - accuracy: 0.9828\n",
      "Epoch 9/31\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0481 - accuracy: 0.9843\n",
      "Epoch 10/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0432 - accuracy: 0.9854\n",
      "Epoch 11/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0413 - accuracy: 0.9860\n",
      "Epoch 12/31\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0378 - accuracy: 0.9872\n",
      "Epoch 13/31\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0343 - accuracy: 0.9887\n",
      "Epoch 14/31\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0335 - accuracy: 0.9885\n",
      "Epoch 15/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0335 - accuracy: 0.9887\n",
      "Epoch 16/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0306 - accuracy: 0.9899\n",
      "Epoch 17/31\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0280 - accuracy: 0.9905\n",
      "Epoch 18/31\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0281 - accuracy: 0.9901\n",
      "Epoch 19/31\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0269 - accuracy: 0.9904\n",
      "Epoch 20/31\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0271 - accuracy: 0.9908\n",
      "Epoch 21/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0246 - accuracy: 0.9915\n",
      "Epoch 22/31\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0245 - accuracy: 0.9916\n",
      "Epoch 23/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0238 - accuracy: 0.9914\n",
      "Epoch 24/31\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0233 - accuracy: 0.9920\n",
      "Epoch 25/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0224 - accuracy: 0.9924\n",
      "Epoch 26/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0216 - accuracy: 0.9927\n",
      "Epoch 27/31\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0225 - accuracy: 0.9924\n",
      "Epoch 28/31\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0198 - accuracy: 0.9938\n",
      "Epoch 29/31\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0198 - accuracy: 0.9929\n",
      "Epoch 30/31\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 31/31\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0192 - accuracy: 0.9933\n",
      "10000/1 - 1s - loss: 0.0455 - accuracy: 0.9807\n",
      "\n",
      "-------------------------> Currently training the model with 32 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/32\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2992 - accuracy: 0.9138\n",
      "Epoch 2/32\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1400 - accuracy: 0.9583\n",
      "Epoch 3/32\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1036 - accuracy: 0.9689\n",
      "Epoch 4/32\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0849 - accuracy: 0.9742\n",
      "Epoch 5/32\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0735 - accuracy: 0.9776\n",
      "Epoch 6/32\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0649 - accuracy: 0.9793\n",
      "Epoch 7/32\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0563 - accuracy: 0.9820\n",
      "Epoch 8/32\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0516 - accuracy: 0.9833\n",
      "Epoch 9/32\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0469 - accuracy: 0.9849\n",
      "Epoch 10/32\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0441 - accuracy: 0.9855\n",
      "Epoch 11/32\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0406 - accuracy: 0.9862\n",
      "Epoch 12/32\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 13/32\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0354 - accuracy: 0.9882\n",
      "Epoch 14/32\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0327 - accuracy: 0.9895\n",
      "Epoch 15/32\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0322 - accuracy: 0.9890\n",
      "Epoch 16/32\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 17/32\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0291 - accuracy: 0.9902\n",
      "Epoch 18/32\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0280 - accuracy: 0.9901\n",
      "Epoch 19/32\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0257 - accuracy: 0.9911\n",
      "Epoch 20/32\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0257 - accuracy: 0.9908\n",
      "Epoch 21/32\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0247 - accuracy: 0.9915\n",
      "Epoch 22/32\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0231 - accuracy: 0.9918\n",
      "Epoch 23/32\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0241 - accuracy: 0.9916\n",
      "Epoch 24/32\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0228 - accuracy: 0.9925\n",
      "Epoch 25/32\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0231 - accuracy: 0.9918\n",
      "Epoch 26/32\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0227 - accuracy: 0.9920\n",
      "Epoch 27/32\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 28/32\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0206 - accuracy: 0.9927\n",
      "Epoch 29/32\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0194 - accuracy: 0.9932\n",
      "Epoch 30/32\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0196 - accuracy: 0.9933\n",
      "Epoch 31/32\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0196 - accuracy: 0.9933\n",
      "Epoch 32/32\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0193 - accuracy: 0.9933\n",
      "10000/1 - 1s - loss: 0.0462 - accuracy: 0.9813\n",
      "\n",
      "-------------------------> Currently training the model with 33 epoch(s) <-------------------------\n",
      "Train on 60000 samples\n",
      "Epoch 1/33\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3033 - accuracy: 0.9110\n",
      "Epoch 2/33\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1477 - accuracy: 0.9560\n",
      "Epoch 3/33\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1083 - accuracy: 0.9673\n",
      "Epoch 4/33\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0887 - accuracy: 0.9733\n",
      "Epoch 5/33\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0761 - accuracy: 0.9767\n",
      "Epoch 6/33\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0654 - accuracy: 0.9801\n",
      "Epoch 7/33\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0613 - accuracy: 0.9804\n",
      "Epoch 8/33\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0538 - accuracy: 0.9823\n",
      "Epoch 9/33\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0496 - accuracy: 0.9837\n",
      "Epoch 10/33\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0450 - accuracy: 0.9853\n",
      "Epoch 11/33\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 0.0409 - accuracy: 0.9863\n",
      "Epoch 12/33\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0400 - accuracy: 0.9869\n",
      "Epoch 13/33\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 14/33\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0355 - accuracy: 0.9879\n",
      "Epoch 15/33\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0339 - accuracy: 0.9886\n",
      "Epoch 16/33\n",
      "50304/60000 [========================>.....] - ETA: 1s - loss: 0.0312 - accuracy: 0.9893"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5bf0d11cadef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n{line}> Currently training the model with {curr_epoch} epoch(s) <{line}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cs510Ass3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for curr_epoch in epoch_set:\n",
    "    # Build the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    # Get the predictions\n",
    "    predictions = model(x_train[:1]).numpy()\n",
    "\n",
    "    # Select the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    line = \"-------------------------\"\n",
    "    print(f'\\n{line}> Currently training the model with {curr_epoch} epoch(s) <{line}')\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=curr_epoch)\n",
    "\n",
    "    _, accuracy = model.evaluate(x_test,  y_test, verbose=2)\n",
    "    \n",
    "    graph_epochs.append(curr_epoch)\n",
    "    graph_accuracy.append(accuracy * 100)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(graph_epochs, graph_accuracy)\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.ylabel('% Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rX8mhOLljYeM"
   ],
   "name": "beginner.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cs510Ass3",
   "language": "python",
   "name": "cs510ass3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
